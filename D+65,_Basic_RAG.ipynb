{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/eugenie-kim012/LLMDS4/blob/main/D%2B65%2C_Basic_RAG.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "2b45ccee-329c-49d8-8da3-db0d69b95016",
      "metadata": {
        "id": "2b45ccee-329c-49d8-8da3-db0d69b95016"
      },
      "source": [
        "## **RAG 정복하기**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "id": "FHCCBJgrudy0",
      "metadata": {
        "id": "FHCCBJgrudy0",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "f3af0b6b-258d-4e8d-e31b-8e6d1c626f99"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[?25l     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m0.0/67.3 kB\u001b[0m \u001b[31m?\u001b[0m eta \u001b[36m-:--:--\u001b[0m\r\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m67.3/67.3 kB\u001b[0m \u001b[31m3.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h  Installing build dependencies ... \u001b[?25l\u001b[?25hdone\n",
            "  Getting requirements to build wheel ... \u001b[?25l\u001b[?25hdone\n",
            "  Preparing metadata (pyproject.toml) ... \u001b[?25l\u001b[?25hdone\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m69.2/69.2 kB\u001b[0m \u001b[31m4.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m2.5/2.5 MB\u001b[0m \u001b[31m35.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m304.6/304.6 kB\u001b[0m \u001b[31m21.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m41.8/41.8 kB\u001b[0m \u001b[31m2.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m19.3/19.3 MB\u001b[0m \u001b[31m47.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m45.2/45.2 kB\u001b[0m \u001b[31m3.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m363.4/363.4 MB\u001b[0m \u001b[31m4.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m13.8/13.8 MB\u001b[0m \u001b[31m99.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m24.6/24.6 MB\u001b[0m \u001b[31m76.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m883.7/883.7 kB\u001b[0m \u001b[31m42.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m664.8/664.8 MB\u001b[0m \u001b[31m2.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m211.5/211.5 MB\u001b[0m \u001b[31m5.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m56.3/56.3 MB\u001b[0m \u001b[31m12.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m127.9/127.9 MB\u001b[0m \u001b[31m7.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m207.5/207.5 MB\u001b[0m \u001b[31m6.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m21.1/21.1 MB\u001b[0m \u001b[31m89.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m284.2/284.2 kB\u001b[0m \u001b[31m17.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.9/1.9 MB\u001b[0m \u001b[31m71.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m50.9/50.9 kB\u001b[0m \u001b[31m3.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m101.6/101.6 kB\u001b[0m \u001b[31m6.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m16.4/16.4 MB\u001b[0m \u001b[31m90.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m65.8/65.8 kB\u001b[0m \u001b[31m4.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m55.7/55.7 kB\u001b[0m \u001b[31m3.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m118.5/118.5 kB\u001b[0m \u001b[31m8.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m196.2/196.2 kB\u001b[0m \u001b[31m12.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m105.4/105.4 kB\u001b[0m \u001b[31m7.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m71.2/71.2 kB\u001b[0m \u001b[31m5.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m459.8/459.8 kB\u001b[0m \u001b[31m28.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m4.0/4.0 MB\u001b[0m \u001b[31m90.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m453.1/453.1 kB\u001b[0m \u001b[31m27.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m46.0/46.0 kB\u001b[0m \u001b[31m3.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m86.8/86.8 kB\u001b[0m \u001b[31m5.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h  Building wheel for pypika (pyproject.toml) ... \u001b[?25l\u001b[?25hdone\n"
          ]
        }
      ],
      "source": [
        "!pip install -q langchain langchain-openai langchain-ollama langchain-community langchain-chroma langchain-text-splitters tiktoken huggingface_hub sentence_transformers pypdf grandalf"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "02b24183-bbbb-4baa-9fc1-41e713da9f2e",
      "metadata": {
        "id": "02b24183-bbbb-4baa-9fc1-41e713da9f2e"
      },
      "source": [
        "### **RAG 구축하기 – 기본적인 QA 체인 구성**"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "c81587a1-2ab6-49d6-9b08-1d411f6994ff",
      "metadata": {
        "id": "c81587a1-2ab6-49d6-9b08-1d411f6994ff"
      },
      "source": [
        "**[필요한 라이브러리 호출 및 API키 설정]**"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "mjvLUwLOWYYm",
        "outputId": "38dd3cd0-a9e3-4894-dd30-a529c7f9402d"
      },
      "id": "mjvLUwLOWYYm",
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/drive\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "id": "b40a72d7-6b94-43eb-8e22-b569a785b43e",
      "metadata": {
        "id": "b40a72d7-6b94-43eb-8e22-b569a785b43e"
      },
      "outputs": [],
      "source": [
        "import os\n",
        "os.environ[\"OPENAI_API_KEY\"] = \"yourAPI\""
      ]
    },
    {
      "cell_type": "markdown",
      "id": "17c1b664-d961-43e7-a792-13d048c155e5",
      "metadata": {
        "id": "17c1b664-d961-43e7-a792-13d048c155e5"
      },
      "source": [
        "**[문서 로드/분할 및 벡터 임베딩]**"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install pypdfium2\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "FSOEKDcjXipW",
        "outputId": "34dcc9bf-3b50-47ad-94ad-88d7e22127c4"
      },
      "id": "FSOEKDcjXipW",
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting pypdfium2\n",
            "  Downloading pypdfium2-4.30.1-py3-none-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (48 kB)\n",
            "\u001b[?25l     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m0.0/48.2 kB\u001b[0m \u001b[31m?\u001b[0m eta \u001b[36m-:--:--\u001b[0m\r\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m48.2/48.2 kB\u001b[0m \u001b[31m1.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading pypdfium2-4.30.1-py3-none-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (2.9 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m2.9/2.9 MB\u001b[0m \u001b[31m29.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hInstalling collected packages: pypdfium2\n",
            "Successfully installed pypdfium2-4.30.1\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "id": "0dec2c3e-9227-46b9-9a9a-4d49c59683da",
      "metadata": {
        "id": "0dec2c3e-9227-46b9-9a9a-4d49c59683da",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "25b78ccd-c63f-4029-f69c-29fa71d68806"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.11/dist-packages/pypdfium2/_helpers/textpage.py:80: UserWarning: get_text_range() call with default params will be implicitly redirected to get_text_bounded()\n",
            "  warnings.warn(\"get_text_range() call with default params will be implicitly redirected to get_text_bounded()\")\n"
          ]
        }
      ],
      "source": [
        "from langchain.document_loaders import PyPDFLoader #문서 로드를 위함\n",
        "from langchain.vectorstores import Chroma #벡터 저장을 위함\n",
        "from langchain_text_splitters import RecursiveCharacterTextSplitter # 청크화하기 위함\n",
        "from langchain_openai import OpenAIEmbeddings, ChatOpenAI\n",
        "from langchain_core.runnables import RunnablePassthrough\n",
        "from langchain_core.output_parsers import StrOutputParser\n",
        "from langchain.document_loaders.pdf import PyPDFium2Loader\n",
        "\n",
        "\n",
        "#헌법 PDF 파일 로드\n",
        "loader = PyPDFium2Loader(\"/content/drive/MyDrive/WB/2025JPO/대한민국헌법(헌법)(제00010호)(19880225).pdf\")\n",
        "pages = loader.load_and_split()\n",
        "\n",
        "#PDF 파일을 1000자 청크로 분할\n",
        "text_splitter = RecursiveCharacterTextSplitter(chunk_size=1000, chunk_overlap=100) #청크화\n",
        "docs = text_splitter.split_documents(pages)\n",
        "\n",
        "#ChromaDB에 청크들을 벡터 임베딩으로 저장(OpenAI 임베딩 모델 활용)\n",
        "vectorstore = Chroma.from_documents(docs, OpenAIEmbeddings(model = 'text-embedding-3-small'))\n",
        "retriever = vectorstore.as_retriever()"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "72ba8836-7df8-487b-bef6-b203426406c2",
      "metadata": {
        "id": "72ba8836-7df8-487b-bef6-b203426406c2"
      },
      "source": [
        "**[프롬프트와 모델 선언]**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 8,
      "id": "96b69f0f-f36e-476c-a5d2-03f115722383",
      "metadata": {
        "id": "96b69f0f-f36e-476c-a5d2-03f115722383",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "e21e7013-317b-4bac-9bd4-a5cd86b2cc6c"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.11/dist-packages/langsmith/client.py:272: LangSmithMissingAPIKeyWarning: API key must be provided when using hosted LangSmith API\n",
            "  warnings.warn(\n"
          ]
        }
      ],
      "source": [
        "#GPT 3.5 모델 선언\n",
        "from langchain import hub\n",
        "llm = ChatOpenAI(model=\"gpt-4o-mini\")\n",
        "\n",
        "#Langchain Hub에서 RAG 프롬프트 호출\n",
        "prompt = hub.pull(\"rlm/rag-prompt\")\n",
        "\n",
        "#Retriever로 검색한 유사 문서의 내용을 하나의 string으로 결합\n",
        "def format_docs(docs):\n",
        "    return \"\\n\\n\".join(doc.page_content for doc in docs)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 9,
      "id": "19ce3c78-3b41-4e3e-9ac5-418630207bff",
      "metadata": {
        "id": "19ce3c78-3b41-4e3e-9ac5-418630207bff",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "c0e17f6e-c149-4b53-938e-2342cb610e34"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "ChatPromptTemplate(input_variables=['context', 'question'], input_types={}, partial_variables={}, metadata={'lc_hub_owner': 'rlm', 'lc_hub_repo': 'rag-prompt', 'lc_hub_commit_hash': '50442af133e61576e74536c6556cefe1fac147cad032f4377b60c436e6cdcb6e'}, messages=[HumanMessagePromptTemplate(prompt=PromptTemplate(input_variables=['context', 'question'], input_types={}, partial_variables={}, template=\"You are an assistant for question-answering tasks. Use the following pieces of retrieved context to answer the question. If you don't know the answer, just say that you don't know. Use three sentences maximum and keep the answer concise.\\nQuestion: {question} \\nContext: {context} \\nAnswer:\"), additional_kwargs={})])"
            ]
          },
          "metadata": {},
          "execution_count": 9
        }
      ],
      "source": [
        "prompt"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 10,
      "id": "d9982910-e1fb-449c-a141-8f38d75d6aeb",
      "metadata": {
        "id": "d9982910-e1fb-449c-a141-8f38d75d6aeb",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "c02a6f56-1134-4b09-9b6d-3c79abe19fc6"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[HumanMessagePromptTemplate(prompt=PromptTemplate(input_variables=['context', 'question'], input_types={}, partial_variables={}, template=\"You are an assistant for question-answering tasks. Use the following pieces of retrieved context to answer the question. If you don't know the answer, just say that you don't know. Use three sentences maximum and keep the answer concise.\\nQuestion: {question} \\nContext: {context} \\nAnswer:\"), additional_kwargs={})]"
            ]
          },
          "metadata": {},
          "execution_count": 10
        }
      ],
      "source": [
        "prompt.messages"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "dd876224-af3c-4e5c-b08c-096d2dd40785",
      "metadata": {
        "id": "dd876224-af3c-4e5c-b08c-096d2dd40785"
      },
      "source": [
        "**[Chain 구축]**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 11,
      "id": "06c5ec1c-3a94-449a-bbfd-41498e216a00",
      "metadata": {
        "id": "06c5ec1c-3a94-449a-bbfd-41498e216a00"
      },
      "outputs": [],
      "source": [
        "rag_chain = (\n",
        "    {\"context\": retriever, \"question\": RunnablePassthrough()}\n",
        "    | prompt\n",
        "    | llm\n",
        "    | StrOutputParser()\n",
        ")\n",
        "#앞서 선언한 RAG 구성 요소들을 순서에 맞게 연결하기, 그리고 저장"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 12,
      "id": "02c3f048-f1a6-4e41-bf38-fa4fedd78ae2",
      "metadata": {
        "id": "02c3f048-f1a6-4e41-bf38-fa4fedd78ae2",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "aaba4cb7-3885-4c18-d307-f3c047dcc806"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "국회의원의 의무는 국민에 대한 봉사와 책임을 다하는 것이며, 헌법과 법률을 준수해야 합니다. 또한, 국정의 기본계획과 법률안, 예산안 등을 다루고, 중요한 국정사항에 대해 심의하는 역할을 수행합니다. 국회의원은 또한 공공의 이익을 위해 정치적 중립성을 유지해야 합니다.\n"
          ]
        }
      ],
      "source": [
        "answer = rag_chain.invoke(\"국회의원의 의무는 뭐야?\")\n",
        "print(answer)"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "a01d9795-9da7-4295-80c7-0460f1db3be9",
      "metadata": {
        "id": "a01d9795-9da7-4295-80c7-0460f1db3be9"
      },
      "source": [
        "- Chain 구조 출력"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 13,
      "id": "b721da7b-07fa-43f0-b695-8ea96c216d70",
      "metadata": {
        "id": "b721da7b-07fa-43f0-b695-8ea96c216d70",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "a4023bdc-ca46-4935-f1ba-72b433288f58"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "           +---------------------------------+         \n",
            "           | Parallel<context,question>Input |         \n",
            "           +---------------------------------+         \n",
            "                    **               **                \n",
            "                 ***                   ***             \n",
            "               **                         **           \n",
            "+----------------------+              +-------------+  \n",
            "| VectorStoreRetriever |              | Passthrough |  \n",
            "+----------------------+              +-------------+  \n",
            "                    **               **                \n",
            "                      ***         ***                  \n",
            "                         **     **                     \n",
            "           +----------------------------------+        \n",
            "           | Parallel<context,question>Output |        \n",
            "           +----------------------------------+        \n",
            "                             *                         \n",
            "                             *                         \n",
            "                             *                         \n",
            "                  +--------------------+               \n",
            "                  | ChatPromptTemplate |               \n",
            "                  +--------------------+               \n",
            "                             *                         \n",
            "                             *                         \n",
            "                             *                         \n",
            "                      +------------+                   \n",
            "                      | ChatOpenAI |                   \n",
            "                      +------------+                   \n",
            "                             *                         \n",
            "                             *                         \n",
            "                             *                         \n",
            "                   +-----------------+                 \n",
            "                   | StrOutputParser |                 \n",
            "                   +-----------------+                 \n",
            "                             *                         \n",
            "                             *                         \n",
            "                             *                         \n",
            "                +-----------------------+              \n",
            "                | StrOutputParserOutput |              \n",
            "                +-----------------------+              \n"
          ]
        }
      ],
      "source": [
        "rag_chain.get_graph().print_ascii()"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "831461fe-5ae2-41c4-b8a3-065751ad9a00",
      "metadata": {
        "id": "831461fe-5ae2-41c4-b8a3-065751ad9a00"
      },
      "source": [
        "### **RAG 구축하기 – Memory**"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "3a50f675-fe2d-4d4d-acfb-e8d268e1493e",
      "metadata": {
        "id": "3a50f675-fe2d-4d4d-acfb-e8d268e1493e"
      },
      "source": [
        "**[문서 로드-분할-벡터 저장-Retreiver 생성]**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 14,
      "id": "b7928a7c-882a-4a3e-8504-ea337f9aa264",
      "metadata": {
        "id": "b7928a7c-882a-4a3e-8504-ea337f9aa264",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "03ab1b36-0314-47af-a28a-fe07fb798a86"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.11/dist-packages/pypdfium2/_helpers/textpage.py:80: UserWarning: get_text_range() call with default params will be implicitly redirected to get_text_bounded()\n",
            "  warnings.warn(\"get_text_range() call with default params will be implicitly redirected to get_text_bounded()\")\n"
          ]
        }
      ],
      "source": [
        "from langchain import hub\n",
        "from langchain.document_loaders import PyPDFLoader\n",
        "from langchain.vectorstores import Chroma\n",
        "from langchain_text_splitters import RecursiveCharacterTextSplitter\n",
        "from langchain_openai import OpenAIEmbeddings, ChatOpenAI\n",
        "from langchain_core.runnables import RunnablePassthrough, RunnableParallel\n",
        "from langchain_core.output_parsers import StrOutputParser\n",
        "from langchain_core.runnables.history import BaseChatMessageHistory, RunnableWithMessageHistory\n",
        "\n",
        "# PDF 파일 로드 및 처리\n",
        "loader = PyPDFium2Loader(\"/content/drive/MyDrive/WB/2025JPO/대한민국헌법(헌법)(제00010호)(19880225).pdf\")\n",
        "\n",
        "# 1,000자씩 분할하여 Document 객체 형태로 docs에 저장\n",
        "pages = loader.load_and_split()\n",
        "text_splitter = RecursiveCharacterTextSplitter(chunk_size=1000, chunk_overlap=0)\n",
        "docs = text_splitter.split_documents(pages)\n",
        "\n",
        "# Chroma 벡터 저장소 설정 및 retriever 생성\n",
        "vectorstore = Chroma.from_documents(docs, OpenAIEmbeddings(model='text-embedding-3-small'))\n",
        "retriever = vectorstore.as_retriever()"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "92c04c57-9767-4fdb-95d7-2bf9a9275f39",
      "metadata": {
        "id": "92c04c57-9767-4fdb-95d7-2bf9a9275f39"
      },
      "source": [
        "**[채팅 히스토리와 사용자 질문 통합]**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 15,
      "id": "323a468b-d404-4e50-b231-9905ba997f33",
      "metadata": {
        "id": "323a468b-d404-4e50-b231-9905ba997f33"
      },
      "outputs": [],
      "source": [
        "from langchain.chains.combine_documents import create_stuff_documents_chain\n",
        "from langchain.chains import create_history_aware_retriever, create_retrieval_chain\n",
        "from langchain.prompts import ChatPromptTemplate, MessagesPlaceholder\n",
        "\n",
        "# Define the contextualize question prompt\n",
        "contextualize_q_system_prompt = \"\"\"Given a chat history and the latest user question \\\n",
        "which might reference context in the chat history, formulate a standalone question \\\n",
        "which can be understood without the chat history. Do NOT answer the question, \\\n",
        "just reformulate it if needed and otherwise return it as is.\"\"\"\n",
        "\n",
        "contextualize_q_prompt = ChatPromptTemplate.from_messages(\n",
        "    [\n",
        "        (\"system\", contextualize_q_system_prompt),\n",
        "        MessagesPlaceholder(\"chat_history\"),\n",
        "        (\"human\", \"{input}\"),\n",
        "    ]\n",
        ")\n",
        "history_aware_retriever = create_history_aware_retriever(llm, retriever, contextualize_q_prompt)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 16,
      "id": "67316916-3095-478a-853f-814a052494e1",
      "metadata": {
        "id": "67316916-3095-478a-853f-814a052494e1",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "b1b71b16-593c-4797-e104-aa8b1384ca7b"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "ChatPromptValue(messages=[SystemMessage(content='Given a chat history and the latest user question which might reference context in the chat history, formulate a standalone question which can be understood without the chat history. Do NOT answer the question, just reformulate it if needed and otherwise return it as is.', additional_kwargs={}, response_metadata={}), HumanMessage(content='대통령의 임기는 몇년이야?', additional_kwargs={}, response_metadata={}), AIMessage(content='대통령의 임기는 5년입니다.', additional_kwargs={}, response_metadata={}), HumanMessage(content='국회의원은?', additional_kwargs={}, response_metadata={})])"
            ]
          },
          "metadata": {},
          "execution_count": 16
        }
      ],
      "source": [
        "from langchain_core.messages import AIMessage, HumanMessage\n",
        "\n",
        "contextualize_q_prompt = ChatPromptTemplate.from_messages(\n",
        "    [\n",
        "        (\"system\", contextualize_q_system_prompt),\n",
        "        MessagesPlaceholder(\"chat_history\"),\n",
        "        (\"human\", \"{input}\"),\n",
        "    ]\n",
        ")\n",
        "\n",
        "chat_history = [\n",
        "    HumanMessage(content='대통령의 임기는 몇년이야?'),\n",
        "    AIMessage(content='대통령의 임기는 5년입니다.')\n",
        "]\n",
        "\n",
        "contextualize_q_prompt.invoke({\"input\":\"국회의원은?\", \"chat_history\" : chat_history})"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 17,
      "id": "3249c035-9f7d-4722-bd8c-f5bd87f99b58",
      "metadata": {
        "id": "3249c035-9f7d-4722-bd8c-f5bd87f99b58",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "eeb00c79-2e2a-4b18-b6c8-be49f7f9b31a"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "1번째 유사 청크\n",
            "법제처 2 국가법령정보센터\n",
            "대한민국헌법\n",
            "제74조 ①대통령은 헌법과 법률이 정하는 바에 의하여 국군을 통수한다.\n",
            "②국군의 조직과 편성은 법률로 정한다.\n",
            "제77조 ①대통령은 전시ㆍ사변 또는 이에 준하는 국가비상사태에 있어서 병력으로써 군사상의 필요에 응하거나 공공\n",
            "의 안녕질서를 유지할 필요가 있을 때에는 법률이 정하는 바에 의하여 계엄을 선포할 수 있다.\n",
            "②계엄은 비상계엄과 경비계엄으로 한다.\n",
            "③비상계엄이 선포된 때에는 법률이 정하는 바에 의하여 \n",
            "----------------------------------------------------------------------------------------------------\n",
            "2번째 유사 청크\n",
            "법제처 2 국가법령정보센터\n",
            "대한민국헌법\n",
            "제74조 ①대통령은 헌법과 법률이 정하는 바에 의하여 국군을 통수한다.\n",
            "②국군의 조직과 편성은 법률로 정한다.\n",
            "제77조 ①대통령은 전시ㆍ사변 또는 이에 준하는 국가비상사태에 있어서 병력으로써 군사상의 필요에 응하거나 공공\n",
            "의 안녕질서를 유지할 필요가 있을 때에는 법률이 정하는 바에 의하여 계엄을 선포할 수 있다.\n",
            "②계엄은 비상계엄과 경비계엄으로 한다.\n",
            "③비상계엄이 선포된 때에는 법률이 정하는 바에 의하여 \n",
            "----------------------------------------------------------------------------------------------------\n",
            "3번째 유사 청크\n",
            "법제처 1 국가법령정보센터\n",
            "대한민국헌법\n",
            " \n",
            "대한민국헌법\n",
            "[시행 1988. 2. 25.] [헌법 제10호, 1987. 10. 29., 전부개정]\n",
            " 제1장 총강\n",
            "제1조 ①대한민국은 민주공화국이다.\n",
            "②대한민국의 주권은 국민에게 있고, 모든 권력은 국민으로부터 나온다.\n",
            "제5조 ①대한민국은 국제평화의 유지에 노력하고 침략적 전쟁을 부인한다.\n",
            "②국군은 국가의 안전보장과 국토방위의 신성한 의무를 수행함을 사명으로 하며, 그 정치적 중립성은 준수된다.\n",
            "제7조\n",
            "----------------------------------------------------------------------------------------------------\n",
            "4번째 유사 청크\n",
            "법제처 1 국가법령정보센터\n",
            "대한민국헌법\n",
            " \n",
            "대한민국헌법\n",
            "[시행 1988. 2. 25.] [헌법 제10호, 1987. 10. 29., 전부개정]\n",
            " 제1장 총강\n",
            "제1조 ①대한민국은 민주공화국이다.\n",
            "②대한민국의 주권은 국민에게 있고, 모든 권력은 국민으로부터 나온다.\n",
            "제5조 ①대한민국은 국제평화의 유지에 노력하고 침략적 전쟁을 부인한다.\n",
            "②국군은 국가의 안전보장과 국토방위의 신성한 의무를 수행함을 사명으로 하며, 그 정치적 중립성은 준수된다.\n",
            "제7조\n",
            "----------------------------------------------------------------------------------------------------\n"
          ]
        }
      ],
      "source": [
        "history_aware_retriever = create_history_aware_retriever(llm, retriever, contextualize_q_prompt)\n",
        "result = history_aware_retriever.invoke({\"input\":\"국회의원은?\", \"chat_history\" : chat_history})\n",
        "for i in range(len(result)):\n",
        "    print(f\"{i+1}번째 유사 청크\")\n",
        "    print(result[i].page_content[:250])\n",
        "    print(\"-\"*100)"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "ba3b634e-f714-40d0-9b88-627560d2913a",
      "metadata": {
        "id": "ba3b634e-f714-40d0-9b88-627560d2913a"
      },
      "source": [
        "**[RAG 체인 구축]**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 18,
      "id": "723a8a4d-cead-49b8-9fb4-e27b2f27b776",
      "metadata": {
        "id": "723a8a4d-cead-49b8-9fb4-e27b2f27b776"
      },
      "outputs": [],
      "source": [
        "from langchain.chains import create_retrieval_chain\n",
        "from langchain.chains.combine_documents import create_stuff_documents_chain\n",
        "\n",
        "qa_system_prompt = \"\"\"You are an assistant for question-answering tasks. \\\n",
        "Use the following pieces of retrieved context to answer the question. \\\n",
        "If you don't know the answer, just say that you don't know. \\\n",
        "Use three sentences maximum and keep the answer concise.\\\n",
        "\n",
        "{context}\"\"\"\n",
        "qa_prompt = ChatPromptTemplate.from_messages(\n",
        "    [\n",
        "        (\"system\", qa_system_prompt),\n",
        "        MessagesPlaceholder(\"chat_history\"),\n",
        "        (\"human\", \"{input}\"),\n",
        "    ]\n",
        ")\n",
        "\n",
        "\n",
        "question_answer_chain = create_stuff_documents_chain(llm, qa_prompt)\n",
        "\n",
        "rag_chain = create_retrieval_chain(history_aware_retriever, question_answer_chain)"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "f6e8b901-474c-453e-bb75-f0338592d2d1",
      "metadata": {
        "id": "f6e8b901-474c-453e-bb75-f0338592d2d1"
      },
      "source": [
        "**[RAG 체인 사용 방법 및 채팅 히스토리 기록]**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 19,
      "id": "8a98e916-b526-43f7-89c3-820d7980c8ce",
      "metadata": {
        "id": "8a98e916-b526-43f7-89c3-820d7980c8ce",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "dba65424-9c02-492d-fc61-464849440851"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "국회의원의 임기는 4년입니다.\n"
          ]
        }
      ],
      "source": [
        "from langchain_core.messages import HumanMessage\n",
        "#채팅 히스토리를 적재하기 위한 리스트\n",
        "chat_history = []\n",
        "\n",
        "question = \"대통령의 임기는 몇년이야?\"\n",
        "#첫 질문에 답변하기 위한 rag_chain 실행\n",
        "ai_msg_1 = rag_chain.invoke({\"input\": question, \"chat_history\": chat_history})\n",
        "#첫 질문과 답변을 채팅 히스토리로 저장\n",
        "chat_history.extend([HumanMessage(content=question), ai_msg_1[\"answer\"]])\n",
        "\n",
        "second_question = \"국회의원은?\"\n",
        "#두번째 질문 입력 시에는 첫번째 질문-답변이 저장된 chat_history가 삽입됨\n",
        "ai_msg_2 = rag_chain.invoke({\"input\": second_question, \"chat_history\": chat_history})\n",
        "\n",
        "print(ai_msg_2[\"answer\"])"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "4bfb6804-ac68-4165-b7a8-1d08f76ddd30",
      "metadata": {
        "id": "4bfb6804-ac68-4165-b7a8-1d08f76ddd30"
      },
      "source": [
        "**[채팅 세션별 기록 자동 저장 RAG 체인 구축]**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 20,
      "id": "444db360-b4db-4e8b-88a2-945df01b21f0",
      "metadata": {
        "id": "444db360-b4db-4e8b-88a2-945df01b21f0"
      },
      "outputs": [],
      "source": [
        "from langchain_community.chat_message_histories import ChatMessageHistory\n",
        "from langchain_core.chat_history import BaseChatMessageHistory\n",
        "from langchain_core.runnables.history import RunnableWithMessageHistory\n",
        "\n",
        "#채팅 세션별 기록 저장 위한 Dictionary 선언\n",
        "store = {}\n",
        "\n",
        "#주어진 session_id 값에 매칭되는 채팅 히스토리 가져오는 함수 선언\n",
        "def get_session_history(session_id: str) -> BaseChatMessageHistory:\n",
        "    if session_id not in store:\n",
        "        store[session_id] = ChatMessageHistory()\n",
        "    return store[session_id]\n",
        "\n",
        "\n",
        "#RunnableWithMessageHistory 모듈로 rag_chain에 채팅 기록 세션별로 자동 저장 기능 추가\n",
        "conversational_rag_chain = RunnableWithMessageHistory(\n",
        "    rag_chain,\n",
        "    get_session_history,\n",
        "    input_messages_key=\"input\",\n",
        "    history_messages_key=\"chat_history\",\n",
        "    output_messages_key=\"answer\",\n",
        ")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 21,
      "id": "e7a90b19-e07d-4bcb-9b80-50e68689ba6a",
      "metadata": {
        "id": "e7a90b19-e07d-4bcb-9b80-50e68689ba6a",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        },
        "outputId": "2e38525e-3f9f-4867-c8fc-d6ddb7244a5e"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'대통령의 임기는 5년입니다.'"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 21
        }
      ],
      "source": [
        "conversational_rag_chain.invoke(\n",
        "    {\"input\": \"대통령의 임기는 몇년이야?\"},\n",
        "    config={\n",
        "        \"configurable\": {\"session_id\": \"240510101\"}\n",
        "    },  # constructs a key \"abc123\" in `store`.\n",
        ")[\"answer\"]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 22,
      "id": "7adf1939-1b83-4735-a18f-1fb54e875d0a",
      "metadata": {
        "id": "7adf1939-1b83-4735-a18f-1fb54e875d0a",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        },
        "outputId": "083c1a41-a235-4645-e8cb-ded2c97b08eb"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'국회의원의 임기는 4년입니다.'"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 22
        }
      ],
      "source": [
        "conversational_rag_chain.invoke(\n",
        "    {\"input\": \"국회의원은?\"},\n",
        "    config={\"configurable\": {\"session_id\": \"240510101\"}},\n",
        ")[\"answer\"]\n"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "c8c28ec1-8aae-4c51-a49e-a1b248a7063c",
      "metadata": {
        "id": "c8c28ec1-8aae-4c51-a49e-a1b248a7063c"
      },
      "source": [
        "### **Open Source LLM으로 RAG 시스템 구축하기**"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "f5c322a4-1235-4360-be64-2679801596fe",
      "metadata": {
        "id": "f5c322a4-1235-4360-be64-2679801596fe"
      },
      "source": [
        "**책에 명시된 Ollama 세팅 및 EEVE 모델 다운로드가 완료되어야 실행 가능한 셀입니다.**\n",
        "*"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 24,
      "id": "3fc54d34-b9f5-4727-9c4c-0e6d63a0c4b7",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "3fc54d34-b9f5-4727-9c4c-0e6d63a0c4b7",
        "outputId": "09649f00-64af-479d-93c5-a425930b9b45"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "PyTorch 버전: 2.6.0+cu124\n",
            "CUDA를 사용할 수 없습니다.\n",
            "CUDA를 사용할 수 없습니다. CPU를 사용합니다.\n",
            "현재 사용 중인 디바이스: cpu\n"
          ]
        }
      ],
      "source": [
        "import torch\n",
        "\n",
        "# PyTorch 버전 확인\n",
        "print(f\"PyTorch 버전: {torch.__version__}\")\n",
        "\n",
        "# CUDA 버전 확인 (CUDA를 사용할 수 있는 경우)\n",
        "if torch.cuda.is_available():\n",
        "    print(f\"CUDA 버전: {torch.version.cuda}\")\n",
        "else:\n",
        "    print(\"CUDA를 사용할 수 없습니다.\")\n",
        "\n",
        "# CUDA 사용 가능 여부 및 디바이스 설정\n",
        "if torch.cuda.is_available():\n",
        "    device = torch.device(\"cuda\")\n",
        "    print(f\"CUDA를 사용할 수 있습니다. 사용 가능한 GPU: {torch.cuda.get_device_name(0)}\")\n",
        "else:\n",
        "    device = torch.device(\"cpu\")\n",
        "    print(\"CUDA를 사용할 수 없습니다. CPU를 사용합니다.\")\n",
        "\n",
        "print(f\"현재 사용 중인 디바이스: {device}\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "e9c55fee-116a-4735-b9e8-8cd055d8f314",
      "metadata": {
        "id": "e9c55fee-116a-4735-b9e8-8cd055d8f314"
      },
      "outputs": [],
      "source": [
        "from langchain_ollama import ChatOllama\n",
        "from langchain_core.output_parsers import StrOutputParser\n",
        "from langchain_core.prompts import ChatPromptTemplate\n",
        "\n",
        "llm = ChatOllama(model=\"EEVE-Korean-10.8B:latest\")\n",
        "prompt = ChatPromptTemplate.from_template(\"{topic}에 대한 짧은 농담을 들려주세요. \")\n",
        "\n",
        "chain = prompt | llm | StrOutputParser()\n",
        "\n",
        "print(chain.invoke({\"topic\": \"우주여행\"}))"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "d1897d73-f8ee-4c1b-97cf-e6e565dfe846",
      "metadata": {
        "id": "d1897d73-f8ee-4c1b-97cf-e6e565dfe846"
      },
      "source": [
        "**모든 요소를 Open Source로 RAG 체인 구축하기**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "f3cd82d3-88d4-40d4-8408-ad009c5ae492",
      "metadata": {
        "id": "f3cd82d3-88d4-40d4-8408-ad009c5ae492"
      },
      "outputs": [],
      "source": [
        "Chroma().delete_collection()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "5285df39-7b8e-4b9a-9522-7eb860ac334b",
      "metadata": {
        "id": "5285df39-7b8e-4b9a-9522-7eb860ac334b"
      },
      "outputs": [],
      "source": [
        "from langchain.document_loaders import PyPDFLoader\n",
        "from langchain_text_splitters import RecursiveCharacterTextSplitter\n",
        "from langchain.embeddings import HuggingFaceEmbeddings\n",
        "from langchain.vectorstores import Chroma\n",
        "from langchain_ollama import ChatOllama\n",
        "from langchain import hub\n",
        "from langchain_core.runnables import RunnablePassthrough\n",
        "from langchain_core.output_parsers import StrOutputParser\n",
        "\n",
        "loader = PyPDFLoader(r\"../data/대한민국헌법(헌법)(제00010호)(19880225).pdf\")\n",
        "pages = loader.load_and_split()\n",
        "\n",
        "text_splitter = RecursiveCharacterTextSplitter(chunk_size=500, chunk_overlap=0)\n",
        "docs = text_splitter.split_documents(pages)\n",
        "\n",
        "model_name = \"jhgan/ko-sbert-nli\"\n",
        "model_kwargs = {'device': 'CUDA'}\n",
        "encode_kwargs = {'normalize_embeddings': True}\n",
        "\n",
        "embedding = HuggingFaceEmbeddings(\n",
        "    model_name=model_name,\n",
        "    model_kwargs=model_kwargs,\n",
        "    encode_kwargs=encode_kwargs\n",
        ")\n",
        "\n",
        "vectorstore = Chroma.from_documents(docs, embedding)\n",
        "retriever = vectorstore.as_retriever()\n",
        "\n",
        "prompt = hub.pull(\"rlm/rag-prompt\")\n",
        "\n",
        "def format_docs(docs):\n",
        "    return \"\\n\\n\".join(doc.page_content for doc in docs)\n",
        "\n",
        "rag_chain = (\n",
        "    {\"context\": retriever|format_docs, \"question\": RunnablePassthrough()}\n",
        "    | prompt\n",
        "    | llm\n",
        "    | StrOutputParser()\n",
        ")"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "8b73b1e4-8aad-4992-91ec-b9c9f2b0b4dc",
      "metadata": {
        "id": "8b73b1e4-8aad-4992-91ec-b9c9f2b0b4dc"
      },
      "source": [
        "**[rag_chain 답변 스트리밍하기]**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "99ffb051-4bcb-4e44-97dd-333972430407",
      "metadata": {
        "id": "99ffb051-4bcb-4e44-97dd-333972430407"
      },
      "outputs": [],
      "source": [
        "for chunk in rag_chain.stream(\"헌법 제 1조 1항이 뭐야\"):\n",
        "    print(chunk, end=\"\", flush=True)"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "provenance": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "display_name": "ruby",
      "language": "python",
      "name": "ruby"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.12.7"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 5
}